{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32e0a1e3-0016-4a32-b719-5c266daf8513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42843796-9c18-49c0-843c-e45c3b70c07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preview:\n",
      "   customer_id  credit_lines_outstanding  loan_amt_outstanding  \\\n",
      "0      8153374                         0           5221.545193   \n",
      "1      7442532                         5           1958.928726   \n",
      "2      2256073                         0           3363.009259   \n",
      "3      4885975                         0           4766.648001   \n",
      "4      4700614                         1           1345.827718   \n",
      "\n",
      "   total_debt_outstanding       income  years_employed  fico_score  default  \n",
      "0             3915.471226  78039.38546               5         605        0  \n",
      "1             8228.752520  26648.43525               2         572        1  \n",
      "2             2027.830850  65866.71246               4         602        0  \n",
      "3             2501.730397  74356.88347               5         612        0  \n",
      "4             1768.826187  23448.32631               6         631        0  \n",
      "\n",
      "Columns: Index(['customer_id', 'credit_lines_outstanding', 'loan_amt_outstanding',\n",
      "       'total_debt_outstanding', 'income', 'years_employed', 'fico_score',\n",
      "       'default'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Loan_Data.csv\")\n",
    "print(\"Dataset preview:\")\n",
    "print(data.head())\n",
    "print(\"\\nColumns:\", data.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d90269-4397-4765-b0f7-08a254191e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Select relevant columns\n",
    "fico_col = \"fico_score\"      \n",
    "default_col = \"default\" \n",
    "data = data[[fico_col, default_col]].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d3a3b10-a075-46f4-b5b5-7f54fa9f4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_buckets = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "095174eb-6006-4f17-9a74-2e64c1c544e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Quantization (MSE) =====\n",
      "Bucket means (quantized values):\n",
      " bucket\n",
      "0    552.611707\n",
      "1    606.751395\n",
      "2    638.579688\n",
      "3    670.346520\n",
      "4    721.524837\n",
      "Name: fico_score, dtype: float64\n",
      "Mean Squared Error = 392.65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Quantization (MSE)\n",
    "\n",
    "data = data.sort_values(fico_col).reset_index(drop=True)\n",
    "data[\"bucket\"] = pd.qcut(data[fico_col], q=n_buckets, labels=False)\n",
    "bucket_means = data.groupby(\"bucket\")[fico_col].mean()\n",
    "\n",
    "\n",
    "mse = np.mean([(row[fico_col] - bucket_means[row[\"bucket\"]])**2 \n",
    "               for _, row in data.iterrows()])\n",
    "\n",
    "print(\"\\n===== Quantization (MSE) =====\")\n",
    "print(\"Bucket means (quantized values):\\n\", bucket_means)\n",
    "print(\"Mean Squared Error =\", round(mse, 2))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83b2a60d-e5e8-4776-ba48-d519d51dd3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Log-Likelihood =====\n",
      "Default probabilities per bucket:\n",
      " {0: 0.3985365853658537, 1: 0.21562658548959918, 2: 0.15133232780291603, 3: 0.100150225338007, 4: 0.054189663823381834}\n",
      "Log-Likelihood = -4321.03\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Log-Likelihood\n",
    "log_likelihood = 0\n",
    "bucket_probs = {}\n",
    "\n",
    "for b, group in data.groupby(\"bucket\"):\n",
    "    ni = len(group)                # total records\n",
    "    ki = group[default_col].sum()  # defaults\n",
    "    pi = ki / ni if ni > 0 else 0.0001  # PD in bucket\n",
    "    \n",
    "    # Store for reference\n",
    "    bucket_probs[b] = pi\n",
    "    \n",
    "    # Log-likelihood term\n",
    "    if 0 < pi < 1:\n",
    "        log_likelihood += ki*np.log(pi) + (ni-ki)*np.log(1-pi)\n",
    "\n",
    "print(\"===== Log-Likelihood =====\")\n",
    "print(\"Default probabilities per bucket:\\n\", bucket_probs)\n",
    "print(\"Log-Likelihood =\", round(log_likelihood, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
